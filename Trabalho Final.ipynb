{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16db70ce",
   "metadata": {},
   "source": [
    "# Felipe Cadar Chamone - Projeto Final\n",
    "\n",
    "## Estimando Correspondências entre Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98bc33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "from tqdm import tqdm\n",
    "import cv2, os\n",
    "import utils.io, utils.hpatches, utils.features\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f53572",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 59/59 [00:01<00:00, 34.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Making the Dataset\n",
    "\n",
    "# Extracting Features\n",
    "viewpoint_data = utils.hpatches.getViewpoint()\n",
    "illumination_data = utils.hpatches.getIlumination()\n",
    "# raw_data = {'viewpoint': viewpoint_data, 'illumination': illumination_data}\n",
    "raw_data = {'viewpoint': viewpoint_data}\n",
    "data_path = './data'\n",
    "extractor_name = 'sift'\n",
    "\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "extractor = cv2.SIFT_create(1024)\n",
    "match_theashold = 2\n",
    "plot_examples = False\n",
    "\n",
    "plot_limit = 0\n",
    "for data_type in raw_data:\n",
    "    for data_name in tqdm(raw_data[data_type]):\n",
    "        paths = sorted(raw_data[data_type][data_name])\n",
    "        \n",
    "        master_path = paths[0]\n",
    "        master_id = master_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        master_result_path = os.path.join(data_path, f\"{extractor_name}/{data_name}/{master_id}\")\n",
    "        \n",
    "        if not (os.path.isfile(master_result_path+\".kps\")) or not (os.path.isfile(master_result_path+\".desc.npz\")):\n",
    "            master_img = cv2.imread(master_path)\n",
    "            master_kps, master_desc = extractor.detectAndCompute(master_img, None)\n",
    "            os.makedirs(os.path.dirname(master_result_path), exist_ok=True)\n",
    "\n",
    "            utils.io.writeCvKps(master_kps, master_result_path)\n",
    "            utils.io.writeDesc(master_desc, master_result_path)\n",
    "        else:\n",
    "            master_kps = utils.io.readKps(master_result_path + '.kps')\n",
    "            master_desc = np.load(master_result_path + '.desc.npz')['desc']\n",
    "        \n",
    "        for image_path in paths[1:]:\n",
    "            plot_limit+=1\n",
    "\n",
    "\n",
    "            \n",
    "            img_id = image_path.split(\"/\")[-1].split(\".\")[0]\n",
    "            result_path = os.path.join(data_path, f\"{extractor_name}/{data_name}/{img_id}\")\n",
    "\n",
    "            if not (os.path.isfile(result_path+\".kps\")) or not (os.path.isfile(result_path+\".desc.npz\")):\n",
    "                img = cv2.imread(image_path)\n",
    "                kps, desc = extractor.detectAndCompute(img, None)\n",
    "                os.makedirs(os.path.dirname(result_path), exist_ok=True)\n",
    "\n",
    "                utils.io.writeCvKps(kps, result_path)\n",
    "                utils.io.writeDesc(desc, result_path)\n",
    "            else:\n",
    "                kps = utils.io.readKps(result_path + '.kps')\n",
    "                desc = np.load(result_path + '.desc.npz')['desc']\n",
    "\n",
    "            \n",
    "            if not os.path.isfile(result_path+'.match'):\n",
    "                H = np.loadtxt(os.path.join( utils.hpatches.HPATCHES_LOCAL, \"data/hpatches-sequences-release\" , data_name, f\"H_1_{img_id}\"))\n",
    "                tgt_kps_np = utils.features.cvToNp(kps)\n",
    "                master_kps_np = utils.features.cvToNp(master_kps)\n",
    "                tgt_kps_gt = utils.hpatches.getGT(master_kps_np, H)\n",
    "                \n",
    "                \n",
    "                dist = scipy.spatial.distance_matrix(tgt_kps_gt, tgt_kps_np)\n",
    "                src, dst = np.where(dist < match_theashold)\n",
    "                match = np.concatenate([src[:, np.newaxis], dst[:, np.newaxis]], 1)\n",
    "                np.savetxt(result_path+'.match', match)\n",
    "            else:\n",
    "\n",
    "                if plot_limit % 20 == 1 and plot_examples:\n",
    "                    master_img = cv2.imread(master_path)\n",
    "                    img = cv2.imread(image_path)\n",
    "                    \n",
    "                    match_np = np.loadtxt(result_path+'.match').astype(int)\n",
    "                    src, dst = match_np[:, 0], match_np[:, 1]\n",
    "                    match = [cv2.DMatch(i, j, 1, 1) for i, j in zip(src, dst)]\n",
    "\n",
    "\n",
    "                    matched_img = cv2.drawMatches(master_img, master_kps, img, kps, match, None)\n",
    "                    plt.figure(figsize=[15, 10])\n",
    "                    plt.imshow(cv2.cvtColor(matched_img, cv2.COLOR_BGR2RGB))\n",
    "                    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df46fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import glob\n",
    "from functools import lru_cache\n",
    "import random\n",
    "\n",
    "class GraphData(Dataset):\n",
    "    def __init__(self, path=\"./data/sift/\", train=True, train_split=0.9):\n",
    "        self.data_path = path\n",
    "        \n",
    "        self.all_matches = sorted(glob.glob(f\"{path}/*/*.match\", recursive=True))\n",
    "        self.imgs_path = utils.hpatches.HPATCHES_LOCAL + \"data/hpatches-sequences-release\"\n",
    "        \n",
    "        random.seed(7891)\n",
    "        random.shuffle(self.all_matches)\n",
    "        \n",
    "        limit = int(len(self.all_matches)*train_split)\n",
    "        if train:\n",
    "            self.all_matches = self.all_matches[:limit]\n",
    "        else:\n",
    "            self.all_matches = self.all_matches[limit:]\n",
    "    \n",
    "#         self.transform = lambda x: torch.tensor(x)\n",
    "        self.transform = ToTensor()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_matches)\n",
    "    \n",
    "    @lru_cache(1)\n",
    "    def getMaster(self, idx):\n",
    "        tgt_path = self.all_matches[idx].split(\"/\")[-1]\n",
    "        master_path = self.all_matches[idx].replace(tgt_path, \"1\")\n",
    "        \n",
    "        cv_kps = utils.io.readKps(master_path+\".kps\")\n",
    "        np_kps = utils.features.cvToNp(cv_kps)\n",
    "        desc = np.load(master_path+\".desc.npz\")['desc']\n",
    "        \n",
    "        return np_kps, desc\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        match_path = self.all_matches[idx]\n",
    "        desc_path = match_path.replace(\".match\", \".desc.npz\")\n",
    "        kps_path = match_path.replace(\".match\", \".kps\")\n",
    "        \n",
    "        match = np.loadtxt(match_path)\n",
    "        master_kps, master_desc = self.getMaster(idx)\n",
    "        tgt_kps = utils.features.cvToNp(utils.io.readKps(kps_path))\n",
    "        tgt_desc = np.load(desc_path)['desc']     \n",
    "        \n",
    "        data_name = match_path.split(\"/\")[-2]\n",
    "        tgt_id = match_path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "            \n",
    "#         if len(match) == 0:\n",
    "#             print(\"AAA\")\n",
    "        \n",
    "        return {\n",
    "            \"kps1\": self.transform(master_kps).float(),\n",
    "            \"desc1\": self.transform(master_desc).float(),\n",
    "            \"kps2\": self.transform(tgt_kps).float(),\n",
    "            \"desc2\": self.transform(tgt_desc).float(),\n",
    "            \"match\": torch.tensor(match).int(),\n",
    "            \"img1\": self.imgs_path + f\"/{data_name}/1.ppm\",\n",
    "            \"img2\": self.imgs_path + f\"/{data_name}/{tgt_id}.ppm\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a482f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GraphData(train=True)\n",
    "test_dataset = GraphData(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cb1b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, in_d: int, out_d: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc1 = nn.Linear(in_d, in_d)\n",
    "        self.fc2 = nn.Linear(in_d, out_d)\n",
    "            \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(d_model, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model: int, nhead: int = 8, nlayers: int = 16, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        dropout = 0.1\n",
    "        self.fc1 = nn.Linear(d_model, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(2,d_model, dropout)\n",
    "#         encoder_layers = TransformerEncoderLayer(d_model, nhead, d_model, dropout)\n",
    "#         self.feat_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        \n",
    "        self.feat_encoder = nn.Sequential(*[MLP(d_model, dropout) for i in range(6)])\n",
    "        \n",
    "    def forward(self, data):\n",
    "        kps1 = data['kps1']\n",
    "        desc1 = data['desc1']\n",
    "        \n",
    "        kps2 = data['kps2']\n",
    "        desc2 = data['desc2']\n",
    "        \n",
    "        n1 = desc1.shape[1]\n",
    "        n2 = desc2.shape[1]\n",
    "        \n",
    "        x1 = self.pos_encoder(kps1) + self.fc1(desc1)\n",
    "        x2 = self.pos_encoder(kps2) + self.fc1(desc2)\n",
    "        \n",
    "#         h = torch.concat([x1, x2], 1)\n",
    "#         h = self.transformer_encoder(h)\n",
    "        \n",
    "#         x1 = h[:, :n1, :]\n",
    "#         x2 = h[:, n1:, :]\n",
    "\n",
    "        x1 = self.feat_encoder(x1)\n",
    "        x2 = self.feat_encoder(x2)\n",
    "\n",
    "        mat = torch.bmm(x1, x2.transpose(1, 2))\n",
    "        \n",
    "        mat = torch.concat([mat, torch.zeros_like(mat[:,:,:1])], 2)\n",
    "        mat = torch.concat([mat, torch.zeros_like(mat[:,:1,:])], 1)\n",
    "\n",
    "        match12 = F.log_softmax(mat, 2)\n",
    "        \n",
    "        return match12\n",
    "    \n",
    "def makeGT(m1, match):\n",
    "    np_match = match.int().cpu().numpy()\n",
    "    mat = np.zeros([m1.shape[1], m1.shape[2]])\n",
    "    mat[:, -1] = 1\n",
    "    mat[-1, :] = 1\n",
    "    mat[-1, -1] = 2\n",
    "    mat[np_match[:, 0],np_match[:, 1]] = 2\n",
    "    label1 = torch.tensor(mat).argmax(1)\n",
    "\n",
    "    return label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0287c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder(128)\n",
    "criterion = nn.NLLLoss()\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dacacf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "plot_interval = 50\n",
    "plot_iter = 0\n",
    "total_loss = 0\n",
    "max_epochs = 10000\n",
    "accumulation_steps = 16\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88d92701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/4vjtx4c53532tgcgnczsgk580000gn/T/ipykernel_80681/623639055.py:50: UserWarning: loadtxt: Empty input file: \"./data/sift/v_charing/5.match\"\n",
      "  match = np.loadtxt(match_path)\n",
      "/var/folders/8c/4vjtx4c53532tgcgnczsgk580000gn/T/ipykernel_80681/623639055.py:50: UserWarning: loadtxt: Empty input file: \"./data/sift/v_charing/6.match\"\n",
      "  match = np.loadtxt(match_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 |    10/  265 batches | lr 0.0010 | ms/batch 40.45 | loss  0.58\n",
      "| epoch   1 |     3/  265 batches | lr 0.0010 | ms/batch 38.55 | loss  0.56\n",
      "| epoch   1 |    15/  265 batches | lr 0.0010 | ms/batch 39.23 | loss  0.45\n",
      "| epoch   2 |    10/  265 batches | lr 0.0010 | ms/batch 37.99 | loss  0.44\n",
      "| epoch   3 |     3/  265 batches | lr 0.0010 | ms/batch 36.61 | loss  0.44\n",
      "| epoch   3 |    15/  265 batches | lr 0.0010 | ms/batch 58.68 | loss  0.44\n",
      "| epoch   4 |    10/  265 batches | lr 0.0010 | ms/batch 38.35 | loss  0.43\n",
      "| epoch   5 |     3/  265 batches | lr 0.0010 | ms/batch 38.33 | loss  0.43\n",
      "| epoch   5 |    15/  265 batches | lr 0.0010 | ms/batch 38.77 | loss  0.44\n",
      "| epoch   6 |    10/  265 batches | lr 0.0010 | ms/batch 37.93 | loss  0.43\n",
      "| epoch   7 |     3/  265 batches | lr 0.0010 | ms/batch 50.45 | loss  0.43\n",
      "| epoch   7 |    15/  265 batches | lr 0.0010 | ms/batch 42.48 | loss  0.43\n",
      "| epoch   8 |    10/  265 batches | lr 0.0010 | ms/batch 56.44 | loss  0.43\n",
      "| epoch   9 |     3/  265 batches | lr 0.0010 | ms/batch 35.97 | loss  0.43\n",
      "| epoch   9 |    15/  265 batches | lr 0.0010 | ms/batch 38.42 | loss  0.43\n",
      "| epoch  10 |    10/  265 batches | lr 0.0010 | ms/batch 50.68 | loss  0.43\n",
      "| epoch  11 |     3/  265 batches | lr 0.0010 | ms/batch 35.73 | loss  0.43\n",
      "| epoch  11 |    15/  265 batches | lr 0.0010 | ms/batch 39.57 | loss  0.43\n",
      "| epoch  12 |    10/  265 batches | lr 0.0010 | ms/batch 39.02 | loss  0.43\n",
      "| epoch  13 |     3/  265 batches | lr 0.0010 | ms/batch 35.69 | loss  0.43\n",
      "| epoch  13 |    15/  265 batches | lr 0.0010 | ms/batch 57.91 | loss  0.43\n",
      "| epoch  14 |    10/  265 batches | lr 0.0010 | ms/batch 39.71 | loss  0.43\n",
      "| epoch  15 |     3/  265 batches | lr 0.0010 | ms/batch 35.85 | loss  0.43\n",
      "| epoch  15 |    15/  265 batches | lr 0.0010 | ms/batch 38.04 | loss  0.43\n",
      "| epoch  16 |    10/  265 batches | lr 0.0010 | ms/batch 37.29 | loss  0.43\n",
      "| epoch  17 |     3/  265 batches | lr 0.0010 | ms/batch 47.66 | loss  0.43\n",
      "| epoch  17 |    15/  265 batches | lr 0.0010 | ms/batch 38.34 | loss  0.43\n",
      "| epoch  18 |    10/  265 batches | lr 0.0010 | ms/batch 38.12 | loss  0.43\n",
      "| epoch  19 |     3/  265 batches | lr 0.0010 | ms/batch 39.99 | loss  0.43\n",
      "| epoch  19 |    15/  265 batches | lr 0.0010 | ms/batch 39.43 | loss  0.43\n",
      "| epoch  20 |    10/  265 batches | lr 0.0010 | ms/batch 49.41 | loss  0.43\n",
      "| epoch  21 |     3/  265 batches | lr 0.0010 | ms/batch 36.57 | loss  0.43\n",
      "| epoch  21 |    15/  265 batches | lr 0.0010 | ms/batch 40.22 | loss  0.43\n",
      "| epoch  22 |    10/  265 batches | lr 0.0010 | ms/batch 40.48 | loss  0.43\n",
      "| epoch  23 |     3/  265 batches | lr 0.0010 | ms/batch 36.40 | loss  0.43\n",
      "| epoch  23 |    15/  265 batches | lr 0.0010 | ms/batch 55.89 | loss  0.43\n",
      "| epoch  24 |    10/  265 batches | lr 0.0010 | ms/batch 38.24 | loss  0.43\n",
      "| epoch  25 |     3/  265 batches | lr 0.0010 | ms/batch 40.13 | loss  0.43\n",
      "| epoch  25 |    15/  265 batches | lr 0.0010 | ms/batch 40.45 | loss  0.43\n",
      "| epoch  26 |    10/  265 batches | lr 0.0010 | ms/batch 37.51 | loss  0.43\n",
      "| epoch  27 |     3/  265 batches | lr 0.0010 | ms/batch 48.99 | loss  0.43\n",
      "| epoch  27 |    15/  265 batches | lr 0.0010 | ms/batch 39.16 | loss  0.43\n",
      "| epoch  28 |    10/  265 batches | lr 0.0010 | ms/batch 37.89 | loss  0.43\n",
      "| epoch  29 |     3/  265 batches | lr 0.0010 | ms/batch 36.09 | loss  0.43\n",
      "| epoch  29 |    15/  265 batches | lr 0.0010 | ms/batch 38.80 | loss  0.43\n",
      "| epoch  30 |    10/  265 batches | lr 0.0010 | ms/batch 46.18 | loss  0.43\n",
      "| epoch  31 |     3/  265 batches | lr 0.0010 | ms/batch 35.88 | loss  0.43\n",
      "| epoch  31 |    15/  265 batches | lr 0.0010 | ms/batch 37.97 | loss  0.43\n",
      "| epoch  32 |    10/  265 batches | lr 0.0010 | ms/batch 37.19 | loss  0.43\n",
      "| epoch  33 |     3/  265 batches | lr 0.0010 | ms/batch 35.91 | loss  0.43\n",
      "| epoch  33 |    15/  265 batches | lr 0.0010 | ms/batch 55.88 | loss  0.43\n",
      "| epoch  34 |    10/  265 batches | lr 0.0010 | ms/batch 38.20 | loss  0.43\n",
      "| epoch  35 |     3/  265 batches | lr 0.0010 | ms/batch 36.67 | loss  0.43\n",
      "| epoch  35 |    15/  265 batches | lr 0.0010 | ms/batch 60.39 | loss  0.43\n",
      "| epoch  36 |    10/  265 batches | lr 0.0010 | ms/batch 40.19 | loss  0.43\n",
      "| epoch  37 |     3/  265 batches | lr 0.0010 | ms/batch 55.78 | loss  0.43\n",
      "| epoch  37 |    15/  265 batches | lr 0.0010 | ms/batch 42.81 | loss  0.43\n",
      "| epoch  38 |    10/  265 batches | lr 0.0010 | ms/batch 40.73 | loss  0.43\n",
      "| epoch  39 |     3/  265 batches | lr 0.0010 | ms/batch 42.69 | loss  0.43\n",
      "| epoch  39 |    15/  265 batches | lr 0.0010 | ms/batch 40.53 | loss  0.43\n",
      "| epoch  40 |    10/  265 batches | lr 0.0010 | ms/batch 50.72 | loss  0.43\n",
      "| epoch  41 |     3/  265 batches | lr 0.0010 | ms/batch 40.30 | loss  0.43\n",
      "| epoch  41 |    15/  265 batches | lr 0.0010 | ms/batch 41.71 | loss  0.43\n",
      "| epoch  42 |    10/  265 batches | lr 0.0010 | ms/batch 46.69 | loss  0.43\n",
      "| epoch  43 |     3/  265 batches | lr 0.0010 | ms/batch 60.98 | loss  0.43\n",
      "| epoch  43 |    15/  265 batches | lr 0.0010 | ms/batch 58.40 | loss  0.43\n",
      "| epoch  44 |    10/  265 batches | lr 0.0010 | ms/batch 39.50 | loss  0.43\n",
      "| epoch  45 |     3/  265 batches | lr 0.0010 | ms/batch 37.62 | loss  0.43\n",
      "| epoch  45 |    15/  265 batches | lr 0.0010 | ms/batch 39.69 | loss  0.43\n",
      "| epoch  46 |    10/  265 batches | lr 0.0010 | ms/batch 39.40 | loss  0.43\n",
      "| epoch  47 |     3/  265 batches | lr 0.0010 | ms/batch 50.36 | loss  0.43\n",
      "| epoch  47 |    15/  265 batches | lr 0.0010 | ms/batch 40.50 | loss  0.43\n",
      "| epoch  48 |    10/  265 batches | lr 0.0010 | ms/batch 40.32 | loss  0.43\n",
      "| epoch  49 |     3/  265 batches | lr 0.0010 | ms/batch 38.68 | loss  0.43\n",
      "| epoch  49 |    15/  265 batches | lr 0.0010 | ms/batch 40.31 | loss  0.43\n",
      "| epoch  50 |    10/  265 batches | lr 0.0010 | ms/batch 48.78 | loss  0.43\n",
      "| epoch  51 |     3/  265 batches | lr 0.0010 | ms/batch 37.89 | loss  0.43\n",
      "| epoch  51 |    15/  265 batches | lr 0.0010 | ms/batch 41.38 | loss  0.43\n",
      "| epoch  52 |    10/  265 batches | lr 0.0010 | ms/batch 41.65 | loss  0.43\n",
      "| epoch  53 |     3/  265 batches | lr 0.0010 | ms/batch 39.23 | loss  0.43\n",
      "| epoch  53 |    15/  265 batches | lr 0.0010 | ms/batch 58.27 | loss  0.43\n",
      "| epoch  54 |    10/  265 batches | lr 0.0010 | ms/batch 39.62 | loss  0.43\n",
      "| epoch  55 |     3/  265 batches | lr 0.0010 | ms/batch 37.92 | loss  0.43\n",
      "| epoch  55 |    15/  265 batches | lr 0.0010 | ms/batch 40.20 | loss  0.43\n",
      "| epoch  56 |    10/  265 batches | lr 0.0010 | ms/batch 39.47 | loss  0.43\n",
      "| epoch  57 |     3/  265 batches | lr 0.0010 | ms/batch 49.88 | loss  0.43\n",
      "| epoch  57 |    15/  265 batches | lr 0.0010 | ms/batch 40.25 | loss  0.43\n",
      "| epoch  58 |    10/  265 batches | lr 0.0010 | ms/batch 39.35 | loss  0.43\n",
      "| epoch  59 |     3/  265 batches | lr 0.0010 | ms/batch 38.03 | loss  0.43\n",
      "| epoch  59 |    15/  265 batches | lr 0.0010 | ms/batch 40.01 | loss  0.43\n",
      "| epoch  60 |    10/  265 batches | lr 0.0010 | ms/batch 48.50 | loss  0.43\n",
      "| epoch  61 |     3/  265 batches | lr 0.0010 | ms/batch 37.75 | loss  0.43\n",
      "| epoch  61 |    15/  265 batches | lr 0.0010 | ms/batch 39.75 | loss  0.43\n",
      "| epoch  62 |    10/  265 batches | lr 0.0010 | ms/batch 39.80 | loss  0.43\n",
      "| epoch  63 |     3/  265 batches | lr 0.0010 | ms/batch 38.39 | loss  0.43\n",
      "| epoch  63 |    15/  265 batches | lr 0.0010 | ms/batch 58.10 | loss  0.43\n",
      "| epoch  64 |    10/  265 batches | lr 0.0010 | ms/batch 39.84 | loss  0.43\n",
      "| epoch  65 |     3/  265 batches | lr 0.0010 | ms/batch 38.26 | loss  0.43\n",
      "| epoch  65 |    15/  265 batches | lr 0.0010 | ms/batch 40.29 | loss  0.43\n",
      "| epoch  66 |    10/  265 batches | lr 0.0010 | ms/batch 39.84 | loss  0.43\n",
      "| epoch  67 |     3/  265 batches | lr 0.0010 | ms/batch 50.50 | loss  0.43\n",
      "| epoch  67 |    15/  265 batches | lr 0.0010 | ms/batch 40.33 | loss  0.43\n",
      "| epoch  68 |    10/  265 batches | lr 0.0010 | ms/batch 40.06 | loss  0.43\n",
      "| epoch  69 |     3/  265 batches | lr 0.0010 | ms/batch 38.54 | loss  0.43\n",
      "| epoch  69 |    15/  265 batches | lr 0.0010 | ms/batch 40.35 | loss  0.43\n",
      "| epoch  70 |    10/  265 batches | lr 0.0010 | ms/batch 48.75 | loss  0.43\n",
      "| epoch  71 |     3/  265 batches | lr 0.0010 | ms/batch 37.40 | loss  0.43\n",
      "| epoch  71 |    15/  265 batches | lr 0.0010 | ms/batch 39.64 | loss  0.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  72 |    10/  265 batches | lr 0.0010 | ms/batch 39.18 | loss  0.43\n",
      "| epoch  73 |     3/  265 batches | lr 0.0010 | ms/batch 37.62 | loss  0.43\n",
      "| epoch  73 |    15/  265 batches | lr 0.0010 | ms/batch 58.51 | loss  0.43\n",
      "| epoch  74 |    10/  265 batches | lr 0.0010 | ms/batch 40.30 | loss  0.43\n",
      "| epoch  75 |     3/  265 batches | lr 0.0010 | ms/batch 37.78 | loss  0.43\n",
      "| epoch  75 |    15/  265 batches | lr 0.0010 | ms/batch 40.12 | loss  0.43\n",
      "| epoch  76 |    10/  265 batches | lr 0.0010 | ms/batch 40.33 | loss  0.43\n",
      "| epoch  77 |     3/  265 batches | lr 0.0010 | ms/batch 49.64 | loss  0.43\n",
      "| epoch  77 |    15/  265 batches | lr 0.0010 | ms/batch 40.39 | loss  0.43\n",
      "| epoch  78 |    10/  265 batches | lr 0.0010 | ms/batch 39.72 | loss  0.43\n",
      "| epoch  79 |     3/  265 batches | lr 0.0010 | ms/batch 38.52 | loss  0.43\n",
      "| epoch  79 |    15/  265 batches | lr 0.0010 | ms/batch 40.05 | loss  0.43\n",
      "| epoch  80 |    10/  265 batches | lr 0.0010 | ms/batch 49.88 | loss  0.43\n",
      "| epoch  81 |     3/  265 batches | lr 0.0010 | ms/batch 38.45 | loss  0.43\n",
      "| epoch  81 |    15/  265 batches | lr 0.0010 | ms/batch 42.93 | loss  0.43\n",
      "| epoch  82 |    10/  265 batches | lr 0.0010 | ms/batch 39.40 | loss  0.43\n",
      "| epoch  83 |     3/  265 batches | lr 0.0010 | ms/batch 38.63 | loss  0.43\n",
      "| epoch  83 |    15/  265 batches | lr 0.0010 | ms/batch 57.50 | loss  0.43\n",
      "| epoch  84 |    10/  265 batches | lr 0.0010 | ms/batch 39.16 | loss  0.43\n",
      "| epoch  85 |     3/  265 batches | lr 0.0010 | ms/batch 37.50 | loss  0.43\n",
      "| epoch  85 |    15/  265 batches | lr 0.0010 | ms/batch 39.74 | loss  0.43\n",
      "| epoch  86 |    10/  265 batches | lr 0.0010 | ms/batch 39.16 | loss  0.43\n",
      "| epoch  87 |     3/  265 batches | lr 0.0010 | ms/batch 48.74 | loss  0.43\n",
      "| epoch  87 |    15/  265 batches | lr 0.0010 | ms/batch 39.52 | loss  0.43\n",
      "| epoch  88 |    10/  265 batches | lr 0.0010 | ms/batch 39.02 | loss  0.43\n",
      "| epoch  89 |     3/  265 batches | lr 0.0010 | ms/batch 36.83 | loss  0.43\n",
      "| epoch  89 |    15/  265 batches | lr 0.0010 | ms/batch 39.41 | loss  0.43\n",
      "| epoch  90 |    10/  265 batches | lr 0.0010 | ms/batch 47.62 | loss  0.43\n",
      "| epoch  91 |     3/  265 batches | lr 0.0010 | ms/batch 37.47 | loss  0.43\n",
      "| epoch  91 |    15/  265 batches | lr 0.0010 | ms/batch 39.60 | loss  0.43\n",
      "| epoch  92 |    10/  265 batches | lr 0.0010 | ms/batch 39.12 | loss  0.43\n",
      "| epoch  93 |     3/  265 batches | lr 0.0010 | ms/batch 37.52 | loss  0.43\n",
      "| epoch  93 |    15/  265 batches | lr 0.0010 | ms/batch 58.41 | loss  0.43\n",
      "| epoch  94 |    10/  265 batches | lr 0.0010 | ms/batch 39.63 | loss  0.43\n",
      "| epoch  95 |     3/  265 batches | lr 0.0010 | ms/batch 38.30 | loss  0.43\n",
      "| epoch  95 |    15/  265 batches | lr 0.0010 | ms/batch 40.08 | loss  0.43\n",
      "| epoch  96 |    10/  265 batches | lr 0.0010 | ms/batch 40.17 | loss  0.43\n",
      "| epoch  97 |     3/  265 batches | lr 0.0010 | ms/batch 70.29 | loss  0.43\n",
      "| epoch  97 |    15/  265 batches | lr 0.0010 | ms/batch 39.95 | loss  0.43\n",
      "| epoch  98 |    10/  265 batches | lr 0.0010 | ms/batch 40.26 | loss  0.43\n",
      "| epoch  99 |     3/  265 batches | lr 0.0010 | ms/batch 37.80 | loss  0.43\n",
      "| epoch  99 |    15/  265 batches | lr 0.0010 | ms/batch 40.21 | loss  0.43\n",
      "| epoch 100 |    10/  265 batches | lr 0.0010 | ms/batch 56.39 | loss  0.43\n",
      "| epoch 101 |     3/  265 batches | lr 0.0010 | ms/batch 40.02 | loss  0.43\n",
      "| epoch 101 |    15/  265 batches | lr 0.0010 | ms/batch 41.21 | loss  0.43\n",
      "| epoch 102 |    10/  265 batches | lr 0.0010 | ms/batch 40.48 | loss  0.43\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m y \u001b[38;5;241m=\u001b[39m model(d)\n\u001b[1;32m     11\u001b[0m label \u001b[38;5;241m=\u001b[39m makeGT(y, d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), label)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m accumulation_steps\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "num_batches = len(train_dataset)\n",
    "for epoch in range(max_epochs):\n",
    "    for batch, d in enumerate(train_dataset):\n",
    "        if len(d['match']) == 0:continue\n",
    "        if batch > 16: break\n",
    "            \n",
    "        i+= 1\n",
    "            \n",
    "        y = model(d)\n",
    "        label = makeGT(y, d['match'])\n",
    "\n",
    "        loss = criterion(y.squeeze(0), label)\n",
    "        loss = loss / accumulation_steps\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        if (i+1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if (i+1) % log_interval == 0:\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.4f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "        if (i+1) % plot_interval == 0:\n",
    "            master_img = cv2.imread(d['img1'])\n",
    "            tgt_img = cv2.imread(d['img2'])\n",
    "\n",
    "            np_match = np.concatenate([np.arange(y.shape[1])[:, np.newaxis], y[0].argmax(1).cpu().numpy()[:, np.newaxis] ], 1)\n",
    "            np_match = np_match[np_match[:, 1] != y.shape[2]-1][:-1]\n",
    "            src, dst = np_match[:, 0], np_match[:, 1]\n",
    "            match = [cv2.DMatch(int(ii), int(jj), 1, 1) for ii, jj in np_match]\n",
    "            \n",
    "            gt_match_matrix = np.zeros([d['kps1'].shape[1], d['kps2'].shape[1]], dtype=int)\n",
    "            gt_match_matrix[d['match'][:, 0], d['match'][:, 1]] = 1\n",
    "            mask = np.zeros(len(match), dtype=int)\n",
    "            for j in range(len(mask)):\n",
    "                mask[j] = gt_match_matrix[np_match[j][0], np_match[j][1]]\n",
    "\n",
    "\n",
    "            master_kps = [cv2.KeyPoint(x=p[0], y=p[1], size=1) for p in d['kps1'][0].cpu().numpy()]\n",
    "            tgt_kps    = [cv2.KeyPoint(x=p[0], y=p[1], size=1) for p in d['kps2'][0].cpu().numpy()]\n",
    "\n",
    "            matched_img = cv2.drawMatches(master_img, master_kps, tgt_img, tgt_kps, match, None, matchesMask=mask)\n",
    "            cv2.imwrite(f\"{i+1}.png\", matched_img)\n",
    "#             plt.figure(figsize=[15, 10])\n",
    "#             plt.imshow(cv2.cvtColor(matched_img, cv2.COLOR_BGR2RGB))\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c0b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91719b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np_match[:, 1] >= 3282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(master_kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7cc4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tgt_kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6ba882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
